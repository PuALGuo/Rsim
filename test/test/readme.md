代码旨在研究CNN中输入数据流的内在分布，比如，大于1000的数据占多少

怎么获取keras中间张量的数据变成了第一个难点

1. print 
print 肯定是不行的，直接print输出的是一个张量，即大小信息啥的，没有value

2. session.run
直接在外部没有成功，报错需要feed placehold
查了相关资料，认为中间张量不存在数据，只是一个占位符，当数据流经过的时候才能存在数据，当外部直接调用的时候，
实际上没有数据流经过（evaluate阶段才有，结束后就没了），所以意思是如果要这样打印，这函数得在模型中间？

3. print_tensor
keras给出了一个后端函数print_tensor，专门用来打印中间张量，看到之时欣喜若狂，查看源码发现调用的是tf.print，
tf.print调用的是默认版session.run。
另一个重要点是，print_tensor也是一种占位符，因此在之后必须调用这个参数，不然没有流经过，evaluate不会打印
小老弟搞我啊？

4. 事实上还是用了print_tensor
本来想集成在bit_check里，在判断最后在收集一下数据，但好像调用的层次太复杂，仍然报错需要feed placehold。嗯？我要的
数据确实是输入数据啊，为什么认为没有feed placehold

5. 所以最后是单独用了一个lambda
但这个只能计算单层的数据，不能多次调用，刚开始我还以为这种占位符只能被调用一次，不能被实例化两次，但我把代码复写后，
仍然报错，才发现自己错了
因为总和需要有一个全局变量，这个变量又参与计算，只能是一个占位符，占位符么还只能在外部初始化，在内部调用时这个占
位符的流没有定义，于是又需要feed placehold。当然，办法是有的，我把batch设置为整个数据，然后一次性计算所有数据。
然后，数据爆了，没有精确值了，科学计数法了解一下，这个隐式转换真的骚

接下来时两种解决方案，需要一个个尝试一下：
1. 能不能在其中把张量转变回变量或者numpy，因为网上的例子都是完整的input，而我只是一个0维的输出
2. 把那个全局占位符的流搞定，不再报错需要feed placehold
